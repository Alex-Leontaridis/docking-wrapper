DOCKING WRAPPER: MANUAL TESTING GUIDE
=====================================

This document contains manual tests to verify that all bugs identified in bugs.txt have been fixed.

TEST ENVIRONMENT SETUP
======================
1. Ensure you have the fixed docking wrapper code
2. Install dependencies: pip install -r requirements_enhanced.txt
3. Have test files ready (see test files section below)
4. Set up logging to see detailed output

TEST FILES NEEDED
=================
Create these test files in a test directory:

1. test_protein.pdb:
ATOM      1  N   ALA A   1      27.462  24.337   5.045  1.00 20.00           N  
ATOM      2  CA  ALA A   1      26.336  25.234   5.234  1.00 20.00           C  
ATOM      3  C   ALA A   1      25.085  24.456   5.567  1.00 20.00           C  
ATOM      4  O   ALA A   1      24.000  25.000   5.000  1.00 20.00           O  
END

2. test_ligand.sdf:
     RDKit          3D

  3  3  0  0  0  0  0  0  0  0999 V2000
    0.0000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
    1.0000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0
    0.5000    0.8660    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0
  1  2  1  0
  1  3  1  0
  2  3  1  0
M  END

3. test_vina_output.txt:
-----+------------+----------+----------+
   # |   MODE    |   AFFINITY | RMSD LOWER | RMSD UPPER
-----+------------+----------+----------+----------+
    1 |      1    |    -8.1   |    0.000   |    0.000
    2 |      2    |    -7.8   |    1.234   |    2.345
-----+------------+----------+----------+----------+

4. test_gnina_output.txt:
-----+------------+----------+----------+
   # |   MODE    |   AFFINITY | RMSD LOWER | RMSD UPPER
-----+------------+----------+----------+----------+
    1 |      1    |    -8.2   |    0.000   |    0.000
-----+------------+----------+----------+----------+

5. test_diffdock_confidence.txt:
pose_1.sdf,0.85
pose_2.sdf,0.72
pose_3.sdf,0.68

CRITICAL BUG TESTS
==================

TEST 1: Protein PDBQT Conversion Fix
------------------------------------
Purpose: Verify that PDBQT conversion no longer creates invalid +0.000 format

Steps:
1. Run the PDBQT conversion:
   python scripts/prep_structures.py --protein test_protein.pdb --output test_output

2. Check the generated PDBQT file:
   - Open the generated .pdbqt file
   - Look for atom lines (start with ATOM or HETATM)
   - Verify NO lines contain "+0.000"
   - Verify charge format is proper number (e.g., "  0.000" or " -0.123")

Expected Result:
✅ PDBQT file should be generated without "+0.000" format
✅ All charge values should be proper numbers
✅ File should be readable by Vina without crashes

Manual Check:
- Open generated PDBQT file in text editor
- Search for "+0.000" - should find nothing
- Verify atom lines end with proper AutoDock types (C, N, O, etc.)

TEST 2: Results Parsing Fix
---------------------------
Purpose: Verify that DockingResultsParser works correctly

Steps:
1. Test Vina parsing:
   python -c "
   from scripts.docking_results_parser import DockingResultsParser
   parser = DockingResultsParser()
   results = parser.parse_vina_output('test_vina_output.txt')
   print(f'Vina results: {len(results)} poses found')
   print(f'First pose affinity: {results[0][\"affinity\"]}')
   "

2. Test GNINA parsing:
   python -c "
   from scripts.docking_results_parser import DockingResultsParser
   parser = DockingResultsParser()
   results = parser.parse_gnina_output('test_gnina_output.txt')
   print(f'GNINA results: {len(results)} poses found')
   print(f'First pose affinity: {results[0][\"affinity\"]}')
   "

3. Test DiffDock parsing:
   - Create test_diffdock_output/ directory
   - Add test_diffdock_confidence.txt to it
   - Create dummy pose files: pose_1.sdf, pose_2.sdf, pose_3.sdf
   python -c "
   from scripts.docking_results_parser import DockingResultsParser
   parser = DockingResultsParser()
   results = parser.parse_diffdock_output('test_diffdock_output')
   print(f'DiffDock results: {len(results)} poses found')
   print(f'First pose confidence: {results[0][\"confidence\"]}')
   "

Expected Result:
✅ Vina parsing should return 2 poses with affinities -8.1 and -7.8
✅ GNINA parsing should return 1 pose with affinity -8.2
✅ DiffDock parsing should return 3 poses with confidences 0.85, 0.72, 0.68
✅ No crashes or "parser not defined" errors

MAJOR ISSUE TESTS
=================

TEST 3: MGLTools Path Configuration
-----------------------------------
Purpose: Verify that MGLTools detection works across platforms

Steps:
1. Test automatic detection:
   python -c "
   from config import DockingConfig
   config = DockingConfig()
   print(f'MGLTools path: {config.mgltools_path}')
   print(f'MGLTools valid: {config.validate_mgltools()}')
   "

2. Test environment variable:
   export MGLTOOLS_PATH="/custom/path/to/mgltools"
   python -c "
   from config import DockingConfig
   config = DockingConfig()
   print(f'MGLTools path: {config.mgltools_path}')
   "

3. Test without MGLTools:
   # Temporarily rename MGLTools if installed
   python -c "
   from config import DockingConfig
   config = DockingConfig()
   print(f'MGLTools available: {config.validate_mgltools()}')
   print(f'Should use fallback: {config.mgltools_path is None}')
   "

Expected Result:
✅ Should detect MGLTools if installed
✅ Should use MGLTOOLS_PATH environment variable if set
✅ Should gracefully handle missing MGLTools
✅ Should provide clear error messages about MGLTools status

TEST 4: Error Handling in Docking Steps
---------------------------------------
Purpose: Verify that pipeline stops early when critical steps fail

Steps:
1. Test with missing protein file:
   python scripts/batch_pipeline.py --protein nonexistent.pdb --ligands test_ligand.sdf --engines vina --output test_output

2. Test with missing ligand file:
   python scripts/batch_pipeline.py --protein test_protein.pdb --ligands nonexistent.sdf --engines vina --output test_output

3. Test with invalid docking engine:
   python scripts/batch_pipeline.py --protein test_protein.pdb --ligands test_ligand.sdf --engines nonexistent_engine --output test_output

4. Test with valid inputs but missing external tools:
   # Temporarily rename vina binary if installed
   python scripts/batch_pipeline.py --protein test_protein.pdb --ligands test_ligand.sdf --engines vina --output test_output

Expected Result:
✅ Should fail early with clear error messages
✅ Should not continue processing after critical failures
✅ Should provide specific error information
✅ Should not crash with cryptic error messages

MINOR ISSUE TESTS
=================

TEST 5: Meeko API Updates
-------------------------
Purpose: Verify that deprecated Meeko API calls are fixed

Steps:
1. Check for deprecation warnings:
   python -c "
   import warnings
   warnings.filterwarnings('always')
   from scripts.prep_structures import prepare_ligand_single
   # This should not show deprecation warnings
   "

2. Test ligand preparation:
   python scripts/prep_structures.py --ligand test_ligand.sdf --output test_ligand_output

Expected Result:
✅ No deprecation warnings about Meeko API
✅ Ligand preparation should work without warnings
✅ Should use current Meeko API with fallback

TEST 6: Dependency Checking
---------------------------
Purpose: Verify that missing dependencies are caught early

Steps:
1. Test dependency checker:
   python scripts/check_dependencies.py

2. Test with missing dependency:
   # Temporarily rename a Python package directory
   python scripts/check_dependencies.py

Expected Result:
✅ Should show status of all dependencies
✅ Should provide clear installation instructions for missing packages
✅ Should exit gracefully with helpful error messages

TEST 7: DiffDock Dummy Detection
--------------------------------
Purpose: Verify improved DiffDock dummy detection

Steps:
1. Test with dummy DiffDock:
   python scripts/run_docking_multi.py --engine diffdock --protein test_protein.pdb --ligand test_ligand.sdf

2. Check dummy script output:
   python DiffDock_dummy/inference.py --help

Expected Result:
✅ Should detect dummy DiffDock installation
✅ Should provide clear installation instructions
✅ Should not crash with misleading errors
✅ Should explain how to install real DiffDock

STRUCTURAL PROBLEM TESTS
========================

TEST 8: Centralized Logging
---------------------------
Purpose: Verify consistent logging across modules

Steps:
1. Test logging setup:
   python -c "
   from utils.logging import setup_logging
   logger = setup_logging('TestLogger', 'test.log', 'DEBUG')
   logger.info('Test info message')
   logger.error('Test error message', error_code='FILE_NOT_FOUND')
   logger.warning('Test warning message')
   "

2. Check log file:
   cat test.log

3. Test error codes:
   python -c "
   from utils.logging import ERROR_CODES
   print('Available error codes:')
   for code, number in ERROR_CODES.items():
       print(f'  {code}: {number}')
   "

Expected Result:
✅ Log file should have consistent format
✅ Error messages should include error codes
✅ Log rotation should work
✅ Different log levels should be respected

TEST 9: Configuration Management
--------------------------------
Purpose: Verify configuration system works correctly

Steps:
1. Test configuration creation:
   python -c "
   from config import DockingConfig
   config = DockingConfig()
   config.mgltools_path = '/test/path'
   config.output_dir = '/test/output'
   config.save('test_config.json')
   print('Configuration saved')
   "

2. Test configuration loading:
   python -c "
   from config import DockingConfig
   config = DockingConfig.load('test_config.json')
   print(f'MGLTools path: {config.mgltools_path}')
   print(f'Output dir: {config.output_dir}')
   "

3. Test configuration validation:
   python -c "
   from config import DockingConfig
   config = DockingConfig()
   config.validate()
   print('Configuration is valid')
   "

Expected Result:
✅ Configuration should save and load correctly
✅ Validation should work
✅ Should handle missing or invalid configurations gracefully

INTEGRATION TESTS
=================

TEST 10: Complete Pipeline Test
-------------------------------
Purpose: Verify that all fixes work together

Steps:
1. Run complete pipeline with test files:
   python scripts/batch_pipeline.py --protein test_protein.pdb --ligands test_ligand.sdf --engines vina --output integration_test

2. Check output structure:
   ls -la integration_test/

3. Check logs:
   cat integration_test/logs/batch_log.txt

4. Check results:
   ls -la integration_test/docking_results/
   ls -la integration_test/parsed_results/

Expected Result:
✅ Pipeline should complete without crashes
✅ PDBQT conversion should work correctly
✅ Results should be parsed and saved
✅ Logs should be comprehensive and clear
✅ Error handling should be graceful

TEST 11: Cross-Platform Compatibility
-------------------------------------
Purpose: Verify fixes work on different platforms

Steps:
1. Test on Windows (if available):
   - Run all tests above on Windows
   - Check path handling
   - Verify MGLTools detection

2. Test on macOS (if available):
   - Run all tests above on macOS
   - Check MGLTools detection in /Applications
   - Verify path handling

3. Test on Linux:
   - Run all tests above on Linux
   - Check MGLTools detection in /usr/local
   - Verify path handling

Expected Result:
✅ All tests should pass on all platforms
✅ Path detection should work correctly
✅ No platform-specific crashes
✅ Consistent behavior across platforms

PERFORMANCE TESTS
=================

TEST 12: Error Recovery
-----------------------
Purpose: Verify system recovers gracefully from errors

Steps:
1. Test with corrupted input files:
   - Create corrupted PDB file
   - Create corrupted SDF file
   - Run pipeline and check error handling

2. Test with insufficient permissions:
   - Create read-only output directory
   - Run pipeline and check error handling

3. Test with disk space issues:
   - Fill disk to 95% capacity
   - Run pipeline and check error handling

Expected Result:
✅ Should provide clear error messages
✅ Should not crash or hang
✅ Should clean up temporary files
✅ Should provide recovery suggestions

TEST 13: Memory and Resource Usage
----------------------------------
Purpose: Verify system handles resources efficiently

Steps:
1. Monitor memory usage during pipeline run
2. Check for memory leaks
3. Verify temporary file cleanup
4. Check CPU usage patterns

Expected Result:
✅ Memory usage should be reasonable
✅ No memory leaks
✅ Temporary files should be cleaned up
✅ CPU usage should be appropriate

SUCCESS CRITERIA
================

All tests should pass with the following criteria:

✅ CRITICAL BUGS:
- PDBQT files generated without "+0.000" format
- Results parsing works without crashes
- Vina accepts generated PDBQT files

✅ MAJOR ISSUES:
- MGLTools detection works across platforms
- Pipeline stops early on critical failures
- Clear error messages provided

✅ MINOR ISSUES:
- No deprecation warnings
- Dependencies caught early
- DiffDock dummy detection improved

✅ STRUCTURAL PROBLEMS:
- Consistent logging format
- Configuration system works
- No hardcoded paths

✅ INTEGRATION:
- Complete pipeline works end-to-end
- Cross-platform compatibility
- Graceful error recovery

REPORTING RESULTS
=================

For each test, record:
1. Test name and number
2. Steps executed
3. Expected vs actual results
4. Any errors or warnings
5. Pass/Fail status

Example:
Test 1: Protein PDBQT Conversion Fix
Steps: Ran PDBQT conversion on test_protein.pdb
Expected: No "+0.000" format in output
Actual: PDBQT file generated correctly, no "+0.000" found
Status: ✅ PASS

This testing guide ensures that all identified bugs have been properly fixed and the system works reliably across different scenarios. 